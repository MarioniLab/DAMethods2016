\documentclass{article}
\usepackage[margin=3cm]{geometry}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{color}

\newcommand\revised[1]{\textcolor{red}{#1}}

\newcommand{\supphyperradverify}{1}
\newcommand{\suppweightmedian}{1.3}
\newcommand{\supptransform}{1.4}
\newcommand{\suppintnorm}{2}
\newcommand{\suppedgeR}{3}
\newcommand{\suppcomponorm}{4}
\newcommand{\suppfdr}{5}
\newcommand{\suppinterpret}{6}
\newcommand{\suppannotate}{7}
\newcommand{\suppbmmc}{8}
\newcommand{\suppoverclust}{9}

\newcommand{\suppfighyperrad}{1}
\newcommand{\suppfighypertol}{2}
\newcommand{\suppfigradsim}{3-4}
\newcommand{\suppfigintnorm}{5-6}
\newcommand{\suppfignbdisp}{7}
\newcommand{\suppfigfdr}{8}
\newcommand{\suppfiginterpret}{9}
\newcommand{\suppfigrealextra}{10-14}
\newcommand{\suppfignonlinear}{15}
\newcommand{\suppfigbmmc}{16}
\newcommand{\suppfigbmmcmark}{17}
\newcommand{\suppfigclustersim}{18}
\newcommand{\suppfigclusterreal}{19}

\newcommand{\supptabparam}{1}

\title{Testing for differential abundance in mass cytometry data}
\author{Aaron T. L. Lun$^{1}$, Arianne C. Richard$^{1,2}$ and John C. Marioni$^{1,3,4}$}

\date{
\begin{minipage}{0.9\textwidth}
\begin{flushleft} 
\begin{small}
$^1$Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\
$^2$Cambridge Institute for Medical Research,  University of Cambridge, Wellcome Trust/MRC Building, Hills Road, Cambridge CB2 0XY, United Kingdom \\
$^3$EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom \\
$^4$Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SA, United Kingdom \\
\end{small}
\end{flushleft}
\end{minipage}\\[0.2in]
\today{}
}

\usepackage{setspace}
\spacing{1.5}

\begin{document}
\maketitle

\begin{quote}
\textbf{Abstract:} Mass cytometry is a recently developed technique that allows researchers to simultaneously quantify the expression of many protein markers in each of millions of cells. 
One key challenge is to identify ``differentially abundant'' subpopulations, where the fraction of cells from a given subpopulation differs between biological conditions. 
Here, we present a novel computational strategy for detecting differentially abundant subpopulations.
Our approach quantifies the abundance of subpopulations across the high-dimensional marker space by assigning cells into hyperspheres, thereby avoiding uncertainties introduced by clustering of the data. 
Within each hypersphere, we test for significant changes in the proportion of cells from each biological condition, before using a spatial false discovery rate to correct for multiple testing.
We demonstrate the utility of our approach by applying it to simulated data, where it outperforms a simple clustering-based approach, and to a real data set characterising the reprogramming of murine embryonic fibroblasts to induced pluripotent stem cells, where it detects both known and novel subpopulations.
\end{quote}

\section{Introduction}
Mass cytometry is a recently developed technique that allows researchers to simultaneously characterise the expression of many ($>30$) protein markers in each of millions of cells \cite{ornatsky2008study}.
Briefly, antibodies specific to markers of interest are conjugated to heavy metal isotopes and used to stain a population of cells.
The suspension of stained cells is passed through a nebulizer and single-cell droplets are vaporized to release and ionize the metals.
Finally, the quantity of metal ions produced from each cell is measured by time-of-flight mass spectrometry.
The resolution of mass spectrometry on purified isotopes avoids problems with spectral overlap that are frequently encountered in conventional flow cytometry with fluorescent markers.
This means that more markers can be quantified for each cell, improving resolution of distinct subpopulations and increasing the potential for novel biological insights.
Mass cytometry has enabled deep phenotyping of cellular profiles in a variety of fields including immunology, haematopoietic development and cancer \cite{leipold2015multiparameter,leelatian2015characterizing,hansmann2015mass,bendall2011singlecell,newell2012cytometry,levine2015datadriven}.
This has revealed novel biology such as near-combinatorial diversity of CD8$^+$ T cells in healthy individuals \cite{newell2012cytometry} and a new population of memory B cells expanded in multiple myeloma patients \cite{hansmann2015mass}.

The ability of mass cytometry to assay more markers leads to a concomitant increase in the dimensionality of the data.
This complicates the data analysis as manual gating and visual examination of biaxial plots (as commonly used in flow cytometry) are no longer feasible when multiple marker combinations have to be considered.
Instead, bespoke computational methods are required to extract meaningful biological information from mass cytometry data. 
To this end, a number of software tools have been developed, including SPADE \cite{qiu2011extracting} and X-shift \cite{samusik2016automated}.
These methods have focused on clustering cells into biologically relevant subpopulations based on the ``intensity'' of each marker (i.e., the signal of the corresponding isotope in the mass spectrum) and quantifying the abundance of each subpopulation in the total cell pool.
This exploits the availability of a large number of markers for effectively distinguishing subpopulations.
However, these approaches fail to directly address an important question of multiparameter multi-group experiments -- namely, what differs between groups?

% Setting up gates for 20-30 markers is not feasible if you have to consider combinations of markers.
% If the markers are not independent, the threshold for one marker will be conditional on the thresholds of previously gated markers.
% One situation is when the definition of "high intensity" changes between cell types.
% This would require manual examination of each branch of the gating hierarchy, which is not possible.
% Even under independence, you can separate better on multiple (informative) dimensions than on a single dimension.
% The ratio of the distance within subpopulations to the distance between subpopulations will increase with more dimensions, thus improving resolution.
% This means that you'd have to consider multiple markers at once to get best results, which is not doable manually past 2 dimensions.

To this end, an alternative analytical strategy is to identify subpopulations that change in abundance between biological conditions \revised{\cite{gaudilliere2014delayed,gaudilliere2015implementing}}.
For example, \revised{certain} immune compartments are enriched or depleted following drug treatment or pathogen challenge, and the composition of cell types changes during development and ageing.
Detection of these differentially abundant (DA) subpopulations is useful as it can provide insights into the cause or effect of the biological differences between conditions.
\revised{One specific example is that of} large-scale immunophenotyping efforts by both human and mouse phenotyping consortia \cite{maecker2012standardizing,brown2012international,finak2016standardizing}\revised{, which rely on the identification of subpopulations that change in abundance after \textit{in vivo} perturbations.}
%From a statistical perspective, it is also more straightforward to compare abundances between samples for the same subpopulation than to compare abundances between subpopulations.
%In the former setting, any subpopulation-specific biases (e.g., due to antibody-specific effects) are expected to cancel out and can be ignored, thus simplifying the downstream analysis.
Testing for DA subpopulations \revised{after manual gating} is a routine step in flow cytometry studies \cite{saeys2016computational,mittag2011recent}, but few methods are available to perform this analysis on mass cytometry data.
Indeed, even published protocols for immunophenotyping by mass cytometry \cite{leipold2015multiparameter,leelatian2015characterizing} do not provide any guidance on comparing abundances between samples.

Of the few methods that do exist for performing comparative analyses of mass cytometry data, the typical strategy is to cluster cells from all samples into empirical subpopulations before checking each cluster for characteristics (e.g., marker intensities or cell abundance) that differ between conditions \cite{anchang2016visualization,bruggner2014automated}.
While intuitive, this approach is sensitive to the parametrization of the initial clustering step.
Uncertainty will be introduced into the cluster definitions when the data are noisy or the cells are not clearly separated \cite{kerr2001bootstrapping,ronan2016avoiding}.
This is problematic if a DA subpopulation is incorrectly placed into the same cluster as a non-DA subpopulation\revised{, such that} any change in the former will be masked by the latter.
Conversely, relying only on well-separated clusters will result in loss of power to resolve subpopulations that differ only subtly from one another.
This is a common scenario for markers that are expressed continuously across a range of intensities without clear changes in cellular density at subpopulation boundaries, e.g., CD38 and HLA-DR to mark activated T cells, CD24 and CD38 to define plasmablasts among B cells, and CD25, CD127, and CCR4 for gating regulatory T cells \cite{finak2016standardizing}.
Cluster formation also depends upon the choice of algorithm \cite{datta2003comparisons,wiwie2015comparing}, which can make it difficult to determine the reliability of the clusters.

% - SPADE uses downsampling to avoid loss of rare things, but it still caps the maximum number of clusters; if there's more than 200 subpops, you're in trouble.
% - Merged clusters would still also see a change in marker intensity, so theoretically still could be detected; however, this would be a lot weaker, so power would be reduced.
% - The Anchang paper is more descriptive with regards to abundances. CITRUS will test significance of correlations between abundance and group, so I'll let it go.

Here, we present a DA analysis pipeline for mass cytometry data that does not rely on an initial clustering step.
Cells from multiple samples are assigned to high-dimensional subspaces, and counts for each subspace are tested for significant differences between conditions.
To correct for multiple testing, we present a method to control the spatial false discovery rate.
Significant subspaces are then visualized in lower dimensions, allowing biological expertise to be incorporated during the interpretation of the results.
In this manner, DA subpopulations can be rigorously identified while avoiding the uncertainties and errors associated with clustering.
We demonstrate the use of our pipeline on public data \cite{zunder2015continuous}, where we recover both known and previously uncharacterised subpopulations that change in abundance across a reprogramming time course.

\section{Results}
\subsection{Overview of the differential abundance pipeline}
Our analysis pipeline for detecting differential abundance can be split into three parts (Figure~\ref{fig:overview}). 
Firstly, we assign cells from all samples to hyperspheres in the multi-dimensional marker space.
Each hypersphere contains a subset of cells and is defined by a combination of marker intensities.
We quantify the cell abundance of each hypersphere by counting the number of cells assigned to that hypersphere from each sample.
Secondly, we use the count data for each hypersphere to test for significant differences in cell abundance between conditions.
Finally, we use the hypersphere $p$-values to control the false discovery rate (FDR) across the multi-dimensional space, i.e., the spatial FDR.
Dimensionality reduction is then performed on the significant hyperspheres to visualize DA subpopulations.

\begin{figure}[bt]
\begin{center}
    \includegraphics[width=\textwidth]{Figure1.pdf}
\end{center}
\caption{Schematic of the differential abundance pipeline.
    (a) Cells from samples 1 (pink) or 2 (light blue) are distributed across the multi-dimensional marker space (two markers shown here for simplicity).
    Hyperspheres (yellow, \revised{$h_1$-$h_4$}) centred on selected cells are constructed, and the number of cells from each sample inside each hypersphere is counted.
    (b) Counts for each hypersphere are tested for significant differences between samples.
    This yields a $p$-value representing the evidence against the null hypothesis of no differences.
    (c) Multiple testing correction of hypersphere $p$-values is performed by controlling the spatial FDR.
    Positions of significant hyperspheres are visualized by dimensionality reduction (e.g., PCA), where the expected proportion of false positives is kept below some threshold.
}
\label{fig:overview}
\end{figure}

We demonstrate our approach using data from a study of mouse embryonic fibroblast (MEF) reprogramming \cite{zunder2015continuous}.
In this study, primary and secondary MEFs were reprogrammed to induced pluripotent stem cells.
Primary MEFs expressing green fluorescent protein (GFP) from the endogenous Oct4 locus (Oct4-GFP) were transduced with lentiviruses expressing a doxycycline-inducible suite of reprogramming factors.
Secondary MEFs expressing either GFP or a neomycin resistance gene (Neo) from the endogenous Nanog locus (Nanog-GFP or Nanog-Neo, respectively) already contained doxycycline-inducible reprogramming transgenes.
For each MEF reprogramming system, a time course was constructed by taking samples at 13-15 timepoints between days 0 and 20 (for Oct4-GFP) or 30 (for Nanog-GFP or Nanog-Neo) after doxycycline-induced transgene expression.
All samples from each time course were barcoded, stained with metal-conjugated antibodies and profiled by mass cytometry.
The aim of the original data analysis -- and of our re-analysis -- was to detect subpopulations that change in abundance over time within each reprogramming system.

\subsection{Summarizing the cell distribution with hyperspheres}
Consider a mass cytometry data set with $S$ samples and $M$ markers.
We assume that appropriate transformations (e.g., biexponential \cite{parks2006new}) have been applied to the marker intensities.
We also assume that normalization of marker intensities between samples, if necessary, has already been performed.
In the MEF reprogramming data set, the data from each time course were collected by multiplexing of barcoded samples \cite{zunder2015palladium}, so no normalization of intensities is required between samples.
Each cell in each sample defines a point in the $M$-dimensional space, with coordinates defined by its transformed (and normalized) intensities.

We quantify the abundance of cells across the space by considering $M$-dimensional hyperspheres.
Each hypersphere defines a subspace that is centred at a distinct combination of marker intensities.
All cells lying within the subspace defined by a hypersphere are assigned to that hypersphere.
We count the number of cells from each sample assigned to each hypersphere, yielding $S$ counts per hypersphere.
(While each subspace contains a subset of cells in the population, this should not be confused with a cell subpopulation.
The latter refers to a biologically meaningful or functional subset, while the former is simply an analytical construct used for cell counting.)
Each cell can be counted multiple times if it is assigned to multiple overlapping hyperspheres.
For each marker, we also compute its median intensity for all cells in each hypersphere.
This provides a median-based position for the hypersphere, representing the central location of the subspace around which most of the cells in the hypersphere originated.
The median position is more appropriate than the hypersphere centre when the cells assigned to the hypersphere are not symmetrically distributed around the centre.

%We then test for differences in the counts between samples, to determine whether the cell abundance in that subspace changes between biological conditions.
%Repeating this process for all hyperspheres will identify differentially abundant subspaces.

The radius $r$ of each hypersphere dictates the trade-off between count size (the number of cells assigned to a hypersphere) and spatial resolution (the ability to distinguish between adjacent subspaces).
We set $r=0.5\sqrt{M}$ to offset the increasing sparsity of the data as the number of dimensions increases.
The 0.5 scaling factor represents the acceptable variability of the intensities for each marker.
Specifically, transformed intensities are represented on the $\log_{10}$-scale, so a value of 0.5 ensures that cells with a 10-fold difference in marker expression are routinely assigned to the same hypersphere.
This strategy is motivated by noting that technical or biological variability often results in an order of magnitude difference in observed expression within the same functional subpopulation \cite{ornatsky2008study,zunder2015continuous,zunder2015palladium}.
We verify this choice of $r$ in the MEF reprogramming data where the distance between neighbouring cells increases as a square-root function of $M$ (Section~\supphyperradverify{} of the Supplementary Materials, Supplementary Figure~\suppfighyperrad{}).
Setting the scaling factor to 0.5 also ensures that counts are large enough for further analysis (Supplementary Figure~\suppfighypertol{}).
See Section~\supphyperradverify{} of the Supplementary Materials \revised{along with Supplementary Figures~\suppfigradsim{}} and Supplementary Table~\supptabparam{} for a detailed discussion on the choice of hypersphere radius.

Each hypersphere is also centred at a point defined by an existing cell.
This is necessary because there are an infinite number of hyperspheres in the $M$-dimesional space.
Centring on existing cells ensures that only non-empty hyperspheres are considered.
In practice, we further reduce computational work by only constructing hyperspheres at every (randomly chosen) 10\textsuperscript{th} cell.
This avoids redundant work in high-density subspaces where many of the resulting hyperspheres would be near-identical in terms of their positions and cell counts.
Note that many adjacent hyperspheres will be overlapping -- this has some implications for FDR control, which will be discussed in more detail later.
\revised{Furthermore, calculation of the median-based hypersphere positions uses weighting to account for differences in the numbers of cells between samples, as described in Section~\suppweightmedian{} of the Supplementary Materials.}

\revised{As previously mentioned, we assume that the transformed (and, if necessary, normalized) intensities have already been computed prior to assigning cells to hyperspheres.
Possible transformations are briefly discussed in Section~\supptransform{} of the Supplementary Materials.
For data sets without barcoding across all samples, some strategies are available for handling shifts in marker intensity due to technical differences (e.g., in staining efficiency) between samples.
This includes range-based or warping normalization across batches of separately barcoded samples, and expansion of the hypersphere radius to accommodate the intensity shifts in non-barcoded data sets. 
A description of these methods is provided in Section~\suppintnorm{} of the Supplementary Materials along with Supplementary Figures~\suppfigintnorm{}.}    

\subsection{Testing for differential abundance in each hypersphere}
Once the counts are obtained, each hypersphere can be tested for differential abundance between conditions.
The null hypothesis is that there is no change in the average counts between conditions within each hypersphere.
Testing can be performed with standard methods for analyzing count data such as negative binomial generalized linear models (NB GLMs).
The NB model is useful as it explicitly accounts for the discrete nature of counts while also modelling overdispersion due to biological variability between replicate samples (Supplementary Figure~\suppfignbdisp{}).
\revised{In addition,} GLMs can accommodate complex experimental designs involving multiple factors and covariates.
For example, each time course in the MEF reprogramming data set can be modelled by fitting a time-dependent trend to the counts for each hypersphere.

We can implement NB GLMs using standard methods in statistical software like R, or through existing R packages like edgeR \cite{robinson2010edgeR} or DESeq2 \cite{love2014moderated}.
The latter were originally designed for analyzing read count data from RNA sequencing experiments.
However, the same mathematical framework can be applied to cell counts in mass cytometry data.
In particular, information can be shared across hyperspheres via empirical Bayes \cite{mccarthy2012differential, lund2012detecting}.
This improves estimation of the dispersion parameter in the presence of limited replicates, thus increasing the reliability and power of downstream inferences.
\revised{A brief description of the statistical methods used by edgeR is provided in Section~\suppedgeR{} of the Supplementary Materials.
    We stress that, in our method, the dispersion represents the variability of the cell counts across replicates for each hypersphere, \textit{not} the variability of the marker intensities across cells.}

We also normalize the counts for each hypersphere based on the total number of cells in each sample.
This accounts for differences in the input quantities of cells between different samples.
Specifically, we define the GLM offsets as the log-transformed total number of cells per sample.
This is conceptually equivalent to analyzing the \textit{proportion} of cells in each sample that are located inside each hypersphere.
Note that this approach does not protect against composition effects\revised{, which are discussed in} Section~\suppcomponorm{} of the Supplementary Materials.
We ignore hypersphere-specific biases (e.g., due to \revised{misassignment of cells that have been suboptimally stained}) as these are expected to cancel out when comparing counts from the same hypersphere.
\revised{The use of} barcoding and multiplexing also avoids introducing sample-specific biases related to differences in staining efficiency or machine behaviour.

% The idea is that, if you have systematic suboptimally in staining, you'll underestimate the abundance in one hypersphere and overestimate them in another.
% For example, if you use concentrations that are too high, you'll increase all intensities, underestimate abundances of the low subpopulation, and overestimate the high counterpart.
% Conversely, if you use an inefficient antibody, you'll overestimate the low subpopulation if some cells don't get stained well.

We tested the performance of edgeR using simulations constructed from the MEF reprogramming study (Methods).
The observed type I error rate was close to or below the specified threshold for all tested data sets, simulation schemes and threshold values (Figure~\ref{fig:testtest}a).
\revised{Accurate type I error control indicates that the specificity of edgeR is maintained when applied to counts of cells assigned to hyperspheres.}
We also compared edgeR to the Mann-Whitney test, which is often used to detect differential proportions in flow cytometry data \cite{watson1992significance} and has been applied to mass cytometry data for the same purpose \cite{behbehani2015mass}.
The Mann-Whitney test routinely yields larger $p$-values than edgeR for hyperspheres with extreme log-fold changes in abundance between conditions (Figure~\ref{fig:testtest}b).
This is due to the loss of power from using ranks with small sample sizes in the former.
\revised{In contrast, edgeR is more sensitive as its parametric model accounts for the magnitude of the change in abundance, producing smaller $p$-values at the same log-fold changes.
Thus, these results suggest that the statistical methods in edgeR are} appropriate for detecting differential abundance in mass cytometry data.

\begin{figure}[bt]
    \begin{center}
        \includegraphics[width=\textwidth]{Figure2.pdf}
    \end{center}
\caption{
Performance of edgeR for detecting DA hyperspheres, using simulations based on the MEF reprogramming time courses.
(a) Observed type I error rates with edgeR for each simulated time course with technical or biological variability, constructed by simple or weighted sampling of cells respectively.
Bar heights represent the mean of 10 simulation iterations, with error bars representing standard errors.
The red lines denote the specified thresholds of 0.01 (left) or 0.05 (right).
(b) Log$_{10}$-ratios of the $p$-values computed by edgeR against those from the Mann-Whitney (MW) test, plotted against log$_{2}$-fold changes.
Simulations were performed using weighted sampling for the Oct4-GFP time course, and each hypersphere was tested for differential abundance.
Coloured points represent hyperspheres with absolute log-fold changes greater than two and $p$-values that are smaller in edgeR compared to the MW test (purple) or vice versa (orange).
The number of such hyperspheres is also reported.
The size of each point is determined by the edgeR $p$-value.
}
\label{fig:testtest}
\end{figure}

\subsection{Controlling the spatial false discovery rate}
We define the ``spatial FDR'' as the FDR across the $M$-dimensional space.
\revised{To illustrate, consider the total volume occupied by the set of DA hyperspheres.
    (This is a union rather than a sum of the individual hypersphere volumes, as many hyperspheres are likely to be overlapping.)
    Roughly speaking, the spatial FDR can be interpreted as the proportion of this volume that is occupied by false positive hyperspheres.
    This is not the same as the FDR across the individual hyperspheres, due to the differences in the density of hyperspheres across the space.
    For example, the FDR across hyperspheres in Figure~\ref{fig:fdrexample} is 25\% while the spatial FDR across volume is 50\%.
    This difference in the spatial density of hyperspheres is the main problem with overlapping hyperspheres, as alluded to earlier.}

\begin{figure}[bt]
\begin{center}
\includegraphics[width=\textwidth]{Figure3.pdf}
\end{center}
\caption{\revised{Control of the spatial FDR is roughly equivalent to controlling the FDR across the volume occupied by putative DA hyperspheres.
    Each hypersphere has a median-based position (small circles) and occupies a volume of the high-dimensional space (shown as the dotted ring for a number of hyperspheres).
    The total occupied volume is computed as the union of individual hypersphere volumes.
    Here, two groups of hyperspheres (one containing true positives with genuine differences in abundance, the other containing false positives) occupy a similar total volume $V$ but with different densities.
This results in differences in the FDR across hyperspheres compared to that across the occupied volume.
}}
\label{fig:fdrexample}
\end{figure}

\revised{Here, we present a procedure for controlling the spatial FDR based on the hypersphere $p$-values.
    Briefly, each hypersphere is weighted by the reciprocal of its density (calculated in terms of the neighbouring hyperspheres).
    A weighted version of the Benjamini-Hochberg (BH) method \cite{benjamini1997multiple} is then applied to the $p$-values and weights for all hyperspheres.
    If one were to split the high-dimensional space into non-overlapping partitions of equal volume, the total weight of hyperspheres within each non-empty partition would be similar, i.e., each partition/volume of the space makes a similar contribution to the BH correction, regardless of the number of hyperspheres.
    Thus, weighting allows the FDR to be controlled across volume, rather than across hyperspheres.
(See Section~\suppfdr{} of the Supplementary Materials and Supplementary Figure~\suppfigfdr{} for a more detailed description.)}
    The \revised{concept of the spatial} FDR is analogous to the FDR across areas used for three-dimensional data from functional magnetic resonance imaging studies \cite{pacifico2004false,benjamini2007false}, but without the need for clustering or random fields.

We performed simuations based on the MEF reprogramming data to test the use of density-based weights (Methods).
The weighting method was able to control the \revised{observed} spatial FDR close to or below the specified threshold (Figure~\ref{fig:fdr}).
In comparison, na\"ive application of the BH method (i.e., without weighting) failed to control the spatial FDR.
This is because the na\"ive approach controls the FDR across hyperspheres\revised{, which is generally not equivalent to controlling the FDR across volume (Figure~\ref{fig:fdrexample}).
The weighting approach performs better as it explicitly controls for the latter feature.}

%Overlapping hyperspheres also introduce dependencies between tests, with which the BH method is not guaranteed to work 
%-- however, in practice, the method is robust to dependencies, so this is less of a concern.)
%Some liberalness is still present as the spatial FDR is controlled in $M$-dimensional space while being measured in 2D space after dimensionality reduction.
%Nonetheless, it is clear that density weighting improves the accuracy of spatial FDR control.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.9\textwidth]{Figure4.pdf}
\end{center}
\caption{
    Control of the spatial FDR using the na\"ive and weighted BH methods, in simulations based on the MEF reprogramming time courses.
    The observed spatial FDR was calculated in $M$-dimensional space using \revised{hypercubes of width 0.2 to 1}.
    Bar heights represent the mean of 50 simulation iterations, and the error bars represent standard errors.
    The red line denotes the nominal threshold of 5\%.
}
\label{fig:fdr}
\end{figure}

% The other leading brand is to use regularly-spaced hyperspheres (or hypercubes in a grid of comparable volume to each hypersphere).
% This would avoid the need to use complicated weighting schemes during FDR control, as the FDR across hyperspheres _is_ the spatial FDR (one hypersphere per partition).
% The problem is that you'd need to using low spacings to avoid strong edge effects, especially in high-dimensional space.
% If you set up a grid with 5 points per dimension, even with just 20 markers, you'd have over a trillion points to investigate.
% This is not computationally feasible.
%
% It might be possible to take some shortcuts by exploiting the regular grid pattern.
% If one were counting into hypercubes, one could immediately identify all grid points that a cell could be assigned to, and only consider those.
% However, to avoid edge effects, the spacing would need to be low enough that each cell is likely to be assigned to at least two grid points per dimension.
% (This must be the case if hypercubes are arranged in a brickwork pattern.)
% Just incrementing all the identified grid points would require a time complexity of 2^M per cell for M markers.
% In contrast, the current complexity per hypersphere is closer to sqrt(N)*M, which is a lot more scalable unless you have crazy numbers of cells.
%
% With our approach, we centre on the cells so that the hyperspheres capture relevant parts of the space without needing to define a grid.
% We then handle the differences in density across the space during FDR control.
% This might be more statistically complicated, but it avoids the computational effort of setting up and optimizing the grid search.
% Of course, even if you did have evenly spaced centres, that's no guarantee that the median positions would be similarly even.
% The latter is what is used to summarize each hypersphere, so you'd have to empirically adjust for this anyway.

\subsection{Interpreting the results of the DA analysis}
After controlling the spatial FDR, \revised{several options are available for examining the DA hyperspheres.
We can identify significant hyperspheres that are not redundant to (i.e., do not lie within a certain distance of) hyperspheres with smaller $p$-values -- see Section~\suppinterpret{} of the Supplementary Materials for more details.
The resulting subset of hyperspheres is small enough for detailed inspection of the marker intensities with a graphical interface (Supplementary Figure~\suppfiginterpret{}) to characterise each hypersphere.
A complementary approach is to perform dimensionality reduction on the positions of the putative DA hyperspheres, yielding a low-dimensional representation of the differential subspaces for plotting.}
The plot is annotated based on examination of the marker intensities, incorporating biological expertise on the relationships between specific markers and cell types.
In this manner, biologically relevant subpopulations can be identified from the DA hyperspheres.
(A similar step of manual annotation is necessary for other pipelines like SPADE \cite{anchang2016visualization}.
This is largely unavoidable as it is difficult to incorporate complex biological knowledge into a computational algorithm.)
Our strategy of testing for differences before defining subpopulations ensures that uncertainty in clustering or annotation does not compromise the computed DA statistics.
It also simplifies the interpretation of the results, as only the subset of DA hyperspheres needs to be visualized and annotated.

We applied our pipeline to detect DA subpopulations in each of the three time courses in the MEF reprogramming study.
For each time course, cells from all samples were assigned to hyperspheres.
Each hypersphere was tested for differential abundance over time using edgeR.
Putative DA hyperspheres were defined as those detected at a spatial FDR of 5\%.
In this manner, we detected 7416 DA hyperspheres in the Oct4-GFP time course, 5947 in the Nanog-GFP time course, and \revised{21532} in the Nanog-Neo time course.
We then applied $t$-SNE \cite{van2008visualizing} to the positions of detected hyperspheres to obtain a \revised{two-dimensional} visualization of the DA hyperspheres within a spatial context (Figure~\ref{fig:oct4}).
For data sets with many differential subspaces, we prefer $t$-SNE to PCA as the former provides cleaner separation of the underlying subpopulations.
Here, we focus on the Oct4-GFP time course for brevity (see Supplementary Figures~\suppfigrealextra{} for \revised{the results from} all time courses).

\begin{figure}[p]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{Figure5.pdf}
\end{center}
    \caption{
        Differentially abundant subpopulations in the Oct4-GFP time course, detected at a spatial FDR of 5\%.
        (a) A $t$-SNE plot of the median positions of DA hyperspheres. 
        Each point represents a hypersphere and is coloured according to its average log-fold change in abundance over time.
        Grey points represent hyperspheres with significant but non-linear changes in abundance.
        Subpopulations were annotated based on results in Zunder \emph{et al.} \cite{zunder2015continuous}, with additional distinguishing features for each subpopulation noted in parentheses.
        OSKM: reprogramming factors (Oct4, Sox2, Klf4, c-Myc), NE: non-expressing, MET: mesenchymal-epithelial transition, SC4: partially reprogrammed cell line, ESC: embryonic stem cells, mixed 4F: mixed stoichiometry of the OSKM factors.
        (b) The same plots coloured by the median intensity of selected markers in each hypersphere.
        The colour range for each marker was bounded at the 1\textsuperscript{st} and 99\textsuperscript{th} percentiles of the intensities across all cells.
    }

    \label{fig:oct4}
\end{figure}

We annotated the differential hyperspheres in Figure~\ref{fig:oct4} based on the subpopulations described in the original analysis by Zunder \emph{et al.} \cite{zunder2015continuous}.
(See Section~\suppannotate{} of the Supplementary Materials for details.)
Most of the previously defined subpopulations were DA over the time course, including MEFs with and without overexpression of the reprogramming factors; 
    the ``mixed 4F'' population expressing a mixed stoichiometry of these factors; 
    cells undergoing mesenchymal-to-epithelial transition; 
    and a population similar to the partially reprogrammed SC4 cell line.
We recovered DA subpopulations corresponding to three reprogramming end points, consisting of embryonic stem cell (ESC)-like cells, mesendoderm-like Lin28\textsuperscript{high} cells, and Thy1\textsuperscript{high}mEF-SK4\textsuperscript{high} cells that likely failed to reprogram and instead reverted to a MEF-like phenotype.
In particular, the abundance of MEFs dropped over time while the abundance of ESC-like cells increased, consistent with the effects of reprogramming.
We resolved many of these populations into two subsets based on cell cycle status, as defined by IdU incorporation.
We also identified some distinct DA subpopulations that were not clearly characterised in the original analysis.
Specifically, we observed an increase in potentially apoptotic cells with cleaved Caspase-3;
    a non-linear change in abundance of a subpopulation of SC4-like cells with phosphorylated STAT3, AMPK and PLK1 (Supplementary Figure~\suppfignonlinear{});
    and a decrease in abundance of a subpopulation of cells simultaneously expressing high levels of the MEF marker Thy1 along with the reprogramming factors Sox2 and Oct4.
Thus, our method is able to identify significant changes in abundance even in small or transitional subpopulations.

We also examined changes in abundance at critical junctures in the time course.
Figure~\ref{fig:importanttime} shows the effect of doxycycline-induced transgene expression and doxycycline withdrawal.
In the former, the MEFs decrease in abundance while the mixed 4F population begins to increase, consistent with induction of some of the reprogramming factors.
Upon withdrawal, the mixed 4F and SC4-like subpopulations decrease as cells start to progress towards one of the reprogramming endpoints.
These results indicate that our analysis pipline is capable of recovering known biology, as well as providing greater resolution to identify subtle changes in abundance of previously uncharacterised subpopulations.

\begin{figure}[bt]
    \begin{center}
        \includegraphics[width=\textwidth]{Figure6.pdf}
    \end{center}
    \caption{
        Changes in cell abundance after transgene induction with doxycycline (left) or after doxycyline withdrawal (right) in the Oct4-GFP time course.
        Each point in the $t$-SNE plot represents a differential hypersphere, coloured based on the log-fold change during induction (day 0 to 1) or withdrawal (day 16 to 17).
        A prior of 3 was added to each count to stabilize the log-fold changes.
    }
    \label{fig:importanttime}
\end{figure}

\revised{Finally, we applied our method on another data set \cite{levine2015datadriven} examining the effect of interleukin 10 (IL-10) treatment on bone marrow mononuclear cells (BMMCs) across five healthy donors.
    We were able to detect changes in abundance consistent with the expected biology of IL-10, as well as several interesting DA subpopulations that were not identified by the original study (see Section~\suppbmmc{} of the Supplementary Materials and Supplementary Figures~\suppfigbmmc{}-\suppfigbmmcmark{} for details).
    Importantly, this data set contained matched stimulated and unstimulated samples from each donor.
    This experimental design is easily accommodated by the GLM machinery in edgeR, highlighting the flexibility of our approach.
}

\subsection{Comparing to approaches based on clustering}
As mentioned earlier, existing methods for analyzing mass cytometry data involve an initial clustering step.
\revised{This approach can be easily extended to DA analyses, where the counts for each cluster are tested for differential abundance between conditions.
We compare our hypersphere-based method against two cluster-based approaches -- a custom approach involving hierachical clustering of cells followed by testing with edgeR; and the CITRUS software \cite{bruggner2014automated}, which uses statistical methods developed for microarrays \cite{tusher2001significance}.
While testing for changes in abundance within clusters is intuitive, it is also subject to the performance of the clustering algorithm.
In particular, DA subpopulations that are small or have weak effect sizes may not be captured in a separate cluster, compromising their detection.
}

\revised{To demonstrate, we simulated a simple scenario involving two adjacent subpopulations with opposite changes in abundance between conditions (Supplementary Figure~\suppfigclustersim{}).
These subpopulations were consistently detected as being differentially abundant by our hypersphere-based method but not by most of the cluster-based methods.
This is because clusters cannot be unambiguously defined in this scenario, such that a cluster corresponding to one of the DA subpopulations will include cells from the other subpopulation.
Subsequently, the power to detect this cluster is reduced as the DA log-fold change in one direction is weakened by the contribution from the subpopulation changing in the other direction.
(This effect is mitigated by using a large number of small clusters, which increases the chance that each DA subpopulation will be precisely captured by a cluster.
However, this has some practical issues, which are discussed in Section~\suppoverclust{} of the Supplementary Materials.)}
This is likely to be problematic in all situations where subpopulations are not clearly separated.
Examples include gating strategies commonly used in immunophenotyping to characterise \revised{subsets of} T and B cells \cite{finak2016standardizing}, as well as protocols for isolation of haematopoietic stem cell and progenitor populations \cite{wilson2015combined}.
\revised{In such cases, the use of hyperspheres may be more appropriate because each subspace is tested for differential abundance, even if the underlying biological subpopulations are poorly defined.}

\revised{We also tested the performance of CITRUS for detecting differentially abundant subpopulations across time in the MEF reprogramming data set.
CITRUS did not detect a number of subpopulations that were found by the hypersphere-based method (Supplementary Figure~\suppfigclusterreal{}), nor did it detect any new subpopulations.}
Many of the subpopulations in this data set form a continuous trajectory over time \cite{zunder2015continuous}, so suboptimal cluster formation is expected.
This suggests that the use of hyperspheres is beneficial as it improves the detection of subtle changes in abundance within complex subpopulations that are difficult to cluster.
It also simplifies the analysis by avoiding the issue of cluster parametrization -- for example, choosing an appropriate number of clusters is not a straightforward process.

% Note: CITRUS nukes itself w.r.t. power by having a very stringent abundance threshold (5% of the population). 
% Dropping this threshold would probably get more power, but that runs into the parallel problem of having too many correlated tests. 

\section{Discussion}
In this article, we present a computational method for detecting DA subpopulations from mass cytometry data.
This provides an unbiased interrogation of high-dimensional mass cytometry data, driving the discovery of new subsets that would be missed by manual gating on known markers.
Unlike existing methods, our pipeline performs the differential testing without requiring an initial clustering step or explicit definitions of subpopulations.
This reduces the impact of clustering uncertainty or definition errors on the statistical analysis.
We demonstrate the applicability of our method on a public data set where it detects both known and uncharacterised DA subpopulations across a reprogramming time course.
This is done in a statistically rigorous manner that accounts for experimental variability in the abundances and controls the spatial FDR to reduce detection of spurious differences.
The use of GLMs also allows the pipeline to accommodate complex experimental designs, including those with multiple conditions, blocking factors or varying levels of replication.

%Some markers are more relevant than others for defining subpopulations, e.g., IdU is less useful when all subpopulations have a subset of cycling cells.
%Similarly, the variability of intensities for cells from the same functional subpopulation can differ between markers, such that the importance of changes in intensity will also differ.
%For example, in T cell populations, CD4 expression is typically bimodal with tight peaks of high or low intensity, while CD25 expression varies more continuously.

%Errors in classification may also cause problems in the DA analysis.
%If cells with a continuum of marker intensities are classified as a single subpopulation, any internal changes in abundance will be masked.
%Conversely, if cells are under-clustered, interpretation is complicated as many redundant subpopulations are reported with only minor differences in marker intensities.
%From a statistical perspective, these errors are difficult to control as the null hypothesis is not obvious when clustering cells into subpopulations.
%Many assumptions would probably be needed to construct a ``random'' subpopulation for hypothesis testing.
%Care is also required to ensure that a subpopulation is defined consistently across samples, otherwise spurious differences in abundance may be observed across conditions.

Our analytical pipeline offers several advantages over the original analysis of Zunder \emph{et al.} \cite{zunder2015continuous}.
The latter is mainly descriptive, whereas the error-controlling procedures in our analysis provide a greater degree of confidence as to whether the detected changes in abundance are real.
Figure~\ref{fig:oct4} also uses both visual dimensions to separate subpopulations, while the original analysis reserves one dimension for time.
%This allowed us to detect a novel subpopulation that appeared after induction and expressed both MEF markers and reprogramming factors, suggesting that there may be coexpression of these proteins in early stages of reprogramming.
Thus, our approach displays the results in a manner that enhances resolution of distinct subpopulations.
While this comes at the cost of temporal resolution, our approach is modular so alternative visualization schemes can be easily applied (on the significant hyperspheres, or the cells contained within them) to focus on particular aspects of the data.
For example, methods like SPADE can be applied to organize the detected DA hyperspheres into a tree for visualization of lineages.

A complementary approach to differential analyses is to detect differential marker expression within the same subpopulation.
Given a (manually or automatically defined) subpopulation, the average intensity of a particular marker can be compared between conditions \cite{anchang2016visualization,behbehani2015mass}.
This detects changes in the expression of activation or signalling markers within a subpopulation.
Our pipeline is different in that it tests for changes in the abundance of cells, rather than their marker intensities.
However, these two types of differential events are closely related.
Consider a marker $X$ in subpopulation $Y$ that increases in expression between two conditions. 
In our analysis, this will manifest as the appearance of new subpopulation $Y'$, separated from $Y$ in the high-dimensional space by an increase in the intensity of $X$.
This new subpopulation will then be detected as DA between conditions.
\revised{We observed this effect in our re-analysis of the BMMC data set, where an increase in pSTAT3 levels upon IL-10 stimulation manifested as an increase in the abundances of pSTAT3\textsuperscript{high} subpopulations and a concomitant decrease in the abundances of pSTAT3\textsuperscript{low} subpopulations.}
Thus, changes in intensity can be interpreted as changes in abundance for detection with a DA analysis pipeline.

As mass cytometry becomes more accessible, large-scale experiments containing many conditions and replicates are likely to become increasingly routine.
Indeed, a growing number of studies are using mass cytometry in fields such as immunology, haematopoietic development and cancer.
We anticipate that our differential abundance analysis pipeline will be useful for researchers planning to perform comparative studies with such data sets.

% Talk about GLM LASSO here, don't spend too much time on it.

\section{Methods}

\subsection{Data preparation}
\revised{In this section, we describe the processing of data from the MEF reprogramming study \cite{zunder2015continuous}.
For processing of data from the BMMC study \cite{levine2015datadriven}, see Section~\suppbmmc{} of the Supplementary Materials.}

We obtained de-barcoded flow cytometry standard (FCS) files for each time course from Cytobank \cite{kotecha2010web} (accession number 43324).
We applied the logicle transformation \cite{parks2006new} to the marker intensities in each sample.
The transformation parameters were estimated with the estimateLogicle function from the flowCore package \cite{hahne2009flowcore}, using pooled cells from all samples in each time course.
(This avoids spurious differences from sample-specific transformation.)
We gated out cell events with low intensities for the two DNA markers (Iridium-191 and 193), where the threshold was defined as three median absolute deviations below the median intensity for the pooled cells.
We saved the transformed and gated intensities into new FCS files for processing with our pipeline.
Only the intensities for relevant markers (i.e., no DNA, barcodes) were used for further analysis.
Note that normalization of marker intensities between samples is not required for this data set because the samples in each time course were barcoded and pooled for antibody staining and mass cytometry.
Thus, any technical biases will be present in all samples and will cancel out when samples are compared in the DA analysis.


\subsection{Statistical methods for testing differences}
To compute $p$-values, we used the quasi-likelihood (QL) method in edgeR \cite{lund2012detecting}.
First, we filtered out hyperspheres with an average count below 5.
This improves efficiency by removing tests without enough information to reject the null hypothesis \cite{bourgon2010independent}.
For the remaining hyperspheres, we fitted a mean-dependent trend to the NB dispersion estimates \cite{mccarthy2012differential}.
We fitted a NB GLM to the counts for each hypersphere, using the trended dispersion for each hypersphere and the log-transformed total number of cells as the offset for each sample.
We estimated the QL dispersion from the GLM deviance, and stabilized the estimates by robust empirical Bayes shrinkage \cite{phipson2016robust} towards a second mean-dependent trend.
Finally, we used the QL F-test with a specified contrast to compute a $p$-value for each hypersphere.

For the simulations, we used a design matrix with a one-way layout to fit each GLM.
Contrasts were constructed to test for differences between groups.
For the time course analyses, we used a design matrix constructed from a B-spline basis matrix with a time covariate and 3 degrees of freedom.
Contrasts were constructed to test \revised{whether} all spline coefficients were equal to zero.
This represents a null hypothesis that time has no effect on abundance.
The use of splines \revised{in this model} means that linear and non-linear \revised{trends in abundance} with respect to time can be accommodated.

We also applied the Mann-Whitney test to the simulated data.
For each hypersphere, each count was converted into a proportion of the total number of cells from the corresponding sample.
The Mann-Whitney test was applied to these proportions to test for significant differences between groups.

\subsection{Simulations for assessing type I error control}
We used simulations to determine which testing frameworks were able to control the type I error rate for differential abundance analyses.
For each MEF time course, we pooled cells from all samples in the data set.
We generated new samples by randomly sampling cells from the pool, where each new sample contained the same number of cells as one of the original samples.
We separated the new samples into two groups, counted cells into hyperspheres and tested for differential abundance between groups using edgeR or the Mann-Whitney test.
As all cells were sampled from the same pool, the null hypothesis of constant abundance should be true for each hypersphere.
Thus, the $p$-values computed by each framework should be uniformly distributed.
We calculated the observed type I error rate as the proportion of $p$-values below a specified threshold $\alpha$.
Values of $\alpha=0.01$ and 0.05 were tested.

We used two sampling schemes for this simulation.
The first scheme involved sampling with replacement from the pool, where the probability of sampling each cell was the same.
This is the simplest approach but assumes that only sampling noise contributes to variability between replicates.
In practice, additional biological variability will be present due to differences in the composition of cell populations extracted from replicate animals or cultures.
To represent this, each cell $j$ in the pool was assigned a probability weight $R_{js}$ for sample $s$.
($R_{js}$ was sampled from a Gamma distribution with shape and rate set to 0.01.
These parameters were chosen to yield NB dispersions of 0.5-1.5 per hypersphere, comparable to values observed in Supplementary Figure~\suppfignbdisp{} for real data.
In contrast, the first sampling scheme yields near-zero estimates.)
The probability of sampling cell $j$ in sample $s$ is proportional to $R_{js}$, thus skewing selection towards a particular subset of cells in that sample.
However, as the values of $R_{js}$ differ between samples, the favoured subset will also be different for each replicate.
\revised{Thus,} the weighting introduces extra variability by changing the cell composition between replicates.
\revised{Note that the null hypothesis is still true in this scheme -- this is because $E(R_{js})$ is the same for all samples, which means that the average cell composition is the same between groups.} 

\subsection{Simulations to test control of the spatial FDR}
To demonstrate the subtleties of spatial FDR control, we repeated the above simulations with differential populations.
Each sample was constructed using the weighted sampling scheme described above.
\revised{We then added a further $T_s/10$ cells to each sample $s$, where $T_s$ is the original number of cells in $s$.}
The additional cells were assigned marker intensities of zero for all samples in the first group, and intensities of 1 for all samples in the second group.
This represents a differential subpopulation between groups where a subpopulation at $(0,0, \ldots, 0)$ is lost and a subpopulation at $(1, 1, \ldots, 1)$ is gained.
While more complex differential events can be simulated, we use this simple set-up as we are not interested in the true differences, but rather, their effect on the detection of false positives.

We applied the BH method to the $p$-values for all hyperspheres, either directly or with density weights.
Detected \revised{DA} hyperspheres were defined as those with adjusted $p$-values below 0.05.
To measure the observed spatial FDR across the detected hyperspheres, \revised{we partitioned the $M$-dimensional space into non-overlapping hypercubes with side lengths ranging from 0.2 to 1.
Each DA hypersphere was assigned to the hypercube containing its median-based position.
For each non-empty hypercube, we computed the proportion of its assigned hyperspheres that were not truly differential.
The observed spatial FDR was defined as the mean of these proportions across all non-empty hypercubes.
(See Section~\suppfdr{} of the Supplementary Materials for more details.
Briefly, each hypercube represents a partition of similar volume, from which one hypersphere is chosen as a representative.
The mean proportion is an estimate of the expected proportion of representatives that are false positives.)}
%Supplementary Figure~\suppfigfdr{} also provides a two-dimensional representation of this calculation, using pixels instead of hypercubes for demonstration purposes.

% Note that the assessement hypercube can't be too large, otherwise everything would end up in the same hypercube.
% In general, the widths should be small enough to capture different parts of high-volume subpopulations, though not so small that everything ends up in separate hypercubes.

\subsection{Visualizing the differential hyperspheres}
For each hypersphere detected at a spatial FDR of 5\%, we defined the median-based position as a set of intensity values across all markers.
These values were used to perform $t$-SNE via the Rtsne package (https://cran.r-project.org/web/packages/Rtsne), using a perplexity value of 10.
To colour the plot based on differential abundance, a GLM was fitted to the counts for each hypersphere using a design matrix with time as a covariate.
This yields a log$_2$-fold change in abundance per day for each hypersphere, corresponding to a blue-to-red gradient for negative-to-positive values respectively.
(We assume a linear change in abundance over time to simplify coloration.
This does not affect the significance statistics, which are computed with a spline to account for non-linear trends.)
To colour the plot based on marker intensity, the 1\textsuperscript{st} and 99\textsuperscript{th} percentiles of the intensities for all cells were computed for each marker.
A linear gradient between these two percentiles was constructed using the viridis colour scheme (https://cran.r-project.org/web/packages/viridis).
Each hypersphere was then assigned a colour based on the location of its median marker intensity on the gradient. 

\subsection{Comparing to a cluster-based approach}
We simulated data for an experimental design involving 30 markers and two replicates in each of two conditions.
\revised{For a population of 20000 cells, we sampled intensities for each marker} from a Normal(1, 0.6) distribution.
Each of these cells was randomly allocated to a sample to produce a non-DA population.
We also simulated intensities for two subpopulations of \revised{40} cells each, where the cells from each subpopulation were allocated to samples in one condition only.
\revised{Marker intensities for cells in these subpopulations were sampled from a Normal($x$, 0.3) distribution, where $x=4$ for the first marker in the first subpopulation and $x=2$ otherwise.
This yields two small DA subpopulations that lie adjacent to each other but change in opposite directions between conditions (Supplementary Figure~\suppfigclustersim{}).}

To perform the \revised{custom} cluster-based DA analysis, all cells were used for complete-linkage hierarchical clustering based on the Euclidean distances.
Clusters were defined by cutting the dendrogram \revised{with the cutree command in R} to generate \revised{5-500} clusters.
The number of cells from each sample was counted for each cluster, and these counts were tested for significant differences between conditions using edgeR as previously described.
Correction for multiple testing was performed by directly applying the BH method to the cluster-level $p$-values.
Detected clusters were defined at an FDR of 5\%.
\revised{To run CITRUS (v0.08), the citrus.full command was used with family set to ``classification'', featureType set to ``abundances'' and modelType set to ``sam''.
Downsampling was performed to 1000 cells per sample and the minimum cluster size was set to 5\%, as recommended.
Detected clusters were defined at an FDR of 5\%, as reported by the SAM method.
For our hypersphere-based method, the DA analysis was performed as previously described and hyperspheres were detected at a spatial FDR of 5\%.}

\revised{For the cluster-based methods, the centre of each cluster was defined from the median intensity across its cells for each marker.
We use the cluster centre as a summary of the location of the entire cluster, as this reflects the common use of the median marker intensity to characterise cell clusters in practical applications \cite{qiu2011extracting,bruggner2014automated}.}
Each DA subpopulation was considered to be successfully detected if the centre of a detected cluster was within $0.5\sqrt{M}$ of the subpopulation centre.
\revised{This assessment was repeated} using the median-based positions of DA hyperspheres.
\revised{For each method, we computed the percentage of simulation iterations in which each subpopulation was successfully detected.}

\revised{For real data analyses, the CITRUS command was used with family set to ``continuous" to identify changes in abundance over time. 
    Detected clusters were defined as those reported at a FDR of 5\%.}
    For each detected cluster, \revised{the median-based centre was determined and the hypersphere with the closest position to the cluster centre} in $M$-dimensional space was identified.
Each cluster centre was mapped onto the $t$-SNE plot of DA hyperspheres using the coordinates of its closest hypersphere.
Note that a cluster centre was not mapped if the distance to the closest hypersphere was greater than $0.5\sqrt{M}$.
Any unmapped DA cluster was treated as being undetected by the hypersphere-based approach.

\subsection{Implementation and availablity of code}
Simulation and analysis code were written in R and are accessible at {http://\-github.com/\-MarioniLab/\-DAMethods2016}.
Methods in the DA analysis pipeline were written in a combination of R and C++.
Cell counting, nearest-neighbour detection and density estimation were performed using an approach similar to that in X-shift \cite{samusik2016automated}.
Briefly, $k$-means clustering was performed on all cells, setting $k=\sqrt{N}$ where $N$ is the total number of cells.
Let $|j-t|$ denote the Euclidean distance between cell $j$ and the centre of cluster $t$ in the $M$-dimensional marker space.
Similarly, let $|h-t|$ denote the distance between the centres of $t$ and hypersphere $h$. 
\revised{Both of these distances only need to be computed once per cell -- in the latter case, this is because each hypersphere is centred on a cell.}
By applying the triangle inequality, a cell $j$ in cluster $t$ was only considered for assignment to a hypersphere $h$ if $r + |j-t| \ge |h-t|$.
\revised{For cells not satisfying this requirement, the distance between $j$ and $h$ was not computed to avoid unnecessary work.}
Similarly, $j$ was only considered as a possible neighbour of a cell $j'$ if $d_n + |j-t| \ge |j'-t|$ where $d_n$ is the distance to the current $n$\textsuperscript{th} nearest neighbour (this value is updated during the algorithm once a closer $n$\textsuperscript{th} nearest neighbour is identified).
This speeds up the pipeline while yielding the same results as a na\"ive approach that computes distances between every pair of cells.
On a desktop machine, the analysis takes 10-20 minutes to run for each of the \revised{MEF reprogramming} time courses.
The pipeline is publicly available as the cydar package (mass CYtometry for Differential Abundance analyses in R, http://\-github.com/\-MarioniLab/\-cydar), running on R version 3.3.1 \revised{or higher}.

\section{Author contributions}
ATLL developed the analysis pipeline, tested it with simulations and applied it to the real data. 
ACR interpreted the results to identify the DA subpopulations.
JCM provided direction and advice on the code development and biological interpretation.
All authors wrote and approved the final manuscript.

\section{Acknowledgements}
This work was supported by core funding from Cancer Research UK (award no. A17197).
JCM was also supported by core funding from EMBL.

\section{Supplementary Materials}
The Supplementary Materials is a single PDF file that consists of Sections~1-\suppoverclust{} and contains Supplementary Figures~1-\suppfigclusterreal{} and Supplementary Table~1.
It includes the additional references \cite{lun2016delicious,robinson2010scaling,mccarthy2009treat,ramsay2002applied}.

\bibliography{ref}
\bibliographystyle{unsrt}

\end{document}
